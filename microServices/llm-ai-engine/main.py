"""
AIOT SmolLM2 AI å¼•æ“ä¸»æ‡‰ç”¨ç¨‹å¼æ¨¡çµ„ã€‚

æœ¬æ¨¡çµ„å¯¦ä½œåŸºæ–¼ SmolLM2-135M-Instruct æ¨¡å‹çš„ AI æ¨ç†æœå‹™ï¼Œæä¾›å…©ç¨®æœå‹™æ¨¡å¼ï¼š
- LangChain ç‰ˆæœ¬ï¼šæ”¯æ´å°è©±è¨˜æ†¶ã€RAG æª¢ç´¢å¢å¼·ç”Ÿæˆã€æ–‡æª”ç®¡ç†
- Simple ç‰ˆæœ¬ï¼šè¼•é‡ç´šåŸºç¤æ¨ç†æœå‹™

ä¸»è¦åŠŸèƒ½ï¼š
- å–®è¼ªæ–‡å­—ç”Ÿæˆ
- å°è©±è¨˜æ†¶ç”Ÿæˆï¼ˆLangChain ç‰ˆæœ¬ï¼‰
- ä¸²æµæ–‡å­—ç”Ÿæˆ
- æ–‡æª”ä¸Šå‚³èˆ‡ RAG æª¢ç´¢
- å¥åº·ç‹€æ…‹æª¢æŸ¥
- å°è©±è¨˜æ†¶ç®¡ç†

æŠ€è¡“æ¶æ§‹ï¼š
- FastAPI ä½œç‚º Web æ¡†æ¶
- SmolLM2-135M-Instruct ä½œç‚ºèªè¨€æ¨¡å‹
- æ”¯æ´ CPUã€GPUã€NPU æ¨ç†åŠ é€Ÿ
- CORS è·¨åŸŸæ”¯æ´

Author: AIOT Team
Version: 2.0.0
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
import uvicorn
import logging
import os
from contextlib import asynccontextmanager
from typing import Optional, Dict, Any

from config.llm_config import LLMConfig, DEFAULT_LLM_CONFIG
from services.simple_ai_service import SimpleAIService
from services.langchain_ai_service import LangChainAIService
from models.requests import (
    GenerateRequest, 
    ConversationalRequest, 
    DocumentUploadRequest,
    HealthResponse,
    GenerateResponse
)

# é…ç½®æ—¥èªŒç³»çµ± - çµ±ä¸€æ—¥èªŒæ ¼å¼ï¼ŒåŒ…å«æ™‚é–“æˆ³ã€æ¨¡çµ„åç¨±ã€æ—¥èªŒç´šåˆ¥å’Œè¨Šæ¯å…§å®¹
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å…¨åŸŸ AI æœå‹™å¯¦ä¾‹ - åœ¨æ‡‰ç”¨ç¨‹å¼ç”Ÿå‘½é€±æœŸä¸­ä¿æŒå–®ä¸€å¯¦ä¾‹
ai_service: Optional[Any] = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    è™•ç† FastAPI æ‡‰ç”¨ç¨‹å¼çš„å•Ÿå‹•èˆ‡é—œé–‰äº‹ä»¶ã€‚
    
    æœ¬å‡½æ•¸ç®¡ç† AI æœå‹™çš„å®Œæ•´ç”Ÿå‘½é€±æœŸï¼ŒåŒ…æ‹¬ï¼š
    - æ ¹æ“šç’°å¢ƒè®Šæ•¸é¸æ“‡æœå‹™é¡å‹ï¼ˆLangChain æˆ– Simpleï¼‰
    - å•Ÿå‹•æ™‚åˆå§‹åŒ– AI æœå‹™ä¸¦è¼‰å…¥æ¨¡å‹
    - é—œé–‰æ™‚æ¸…ç†è³‡æºå’Œè¨˜æ†¶é«”
    
    Args:
        app: FastAPI æ‡‰ç”¨ç¨‹å¼å¯¦ä¾‹
        
    Yields:
        None: åœ¨æ‡‰ç”¨ç¨‹å¼é‹è¡ŒæœŸé–“æŒçºŒç›£æ§
        
    Raises:
        Exception: ç•¶ AI æœå‹™åˆå§‹åŒ–å¤±æ•—æ™‚æ‹‹å‡ºç•°å¸¸
        
    Note:
        - å„ªå…ˆä½¿ç”¨ LangChain æœå‹™ï¼Œå¤±æ•—æ™‚è‡ªå‹•é™ç´šç‚º Simple æœå‹™
        - é€é USE_LANGCHAIN ç’°å¢ƒè®Šæ•¸æ§åˆ¶æœå‹™é¡å‹
        - ç¢ºä¿åœ¨æ‡‰ç”¨ç¨‹å¼é—œé–‰æ™‚æ­£ç¢ºé‡‹æ”¾è³‡æº
    """
    global ai_service
    
    # å¾ç’°å¢ƒè®Šæ•¸é¸æ“‡æœå‹™é¡å‹ - é è¨­ä½¿ç”¨ LangChain ç‰ˆæœ¬
    use_langchain = os.getenv("USE_LANGCHAIN", "true").lower() == "true"
    
    # å•Ÿå‹•éšæ®µ - åˆå§‹åŒ– AI æœå‹™
    if use_langchain:
        logger.info("Starting SmolLM2 AI Engine with LangChain...")
        try:
            # å˜—è©¦åˆå§‹åŒ– LangChain AI æœå‹™ï¼ˆåŒ…å«å°è©±è¨˜æ†¶å’Œ RAG åŠŸèƒ½ï¼‰
            ai_service = LangChainAIService(DEFAULT_LLM_CONFIG)
            logger.info("LangChain AI Service initialized successfully")
        except Exception as e:
            # LangChain æœå‹™åˆå§‹åŒ–å¤±æ•—æ™‚ï¼Œè‡ªå‹•é™ç´šç‚º Simple æœå‹™
            logger.error(f"Failed to initialize LangChain AI Service: {e}")
            logger.info("Falling back to Simple AI Service...")
            ai_service = SimpleAIService(DEFAULT_LLM_CONFIG)
            logger.info("Simple AI Service initialized successfully")
    else:
        logger.info("Starting SmolLM2 AI Engine with Simple Service...")
        try:
            # ç›´æ¥ä½¿ç”¨ Simple AI æœå‹™ï¼ˆè¼•é‡ç´šç‰ˆæœ¬ï¼‰
            ai_service = SimpleAIService(DEFAULT_LLM_CONFIG)
            logger.info("Simple AI Service initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize AI Service: {e}")
            raise e
    
    yield  # æ‡‰ç”¨ç¨‹å¼é‹è¡ŒæœŸé–“
    
    # é—œé–‰éšæ®µ - æ¸…ç†è³‡æº
    logger.info("Shutting down SmolLM2 AI Engine...")
    if ai_service:
        ai_service.cleanup()  # æ¸…ç† GPU è¨˜æ†¶é«”å’Œå…¶ä»–è³‡æº

# å»ºç«‹ FastAPI æ‡‰ç”¨ç¨‹å¼å¯¦ä¾‹
# æ ¹æ“šç’°å¢ƒè®Šæ•¸å‹•æ…‹è¨­å®šæœå‹™æè¿°ï¼Œå‘ç”¨æˆ¶èªªæ˜ç•¶å‰æœå‹™æ¨¡å¼çš„åŠŸèƒ½å·®ç•°
use_langchain_desc = os.getenv("USE_LANGCHAIN", "true").lower() == "true"
service_description = (
    "åŸºæ–¼ SmolLM2-135M-Instruct çš„ AI æ¨ç†æœå‹™\n\n"
    + ("ğŸ¦œ **LangChain ç‰ˆæœ¬**: æ”¯æ´å°è©±è¨˜æ†¶ã€RAG æª¢ç´¢å¢å¼·ç”Ÿæˆã€æ–‡æª”ç®¡ç†" 
       if use_langchain_desc 
       else "âš¡ **Simple ç‰ˆæœ¬**: è¼•é‡ç´šåŸºç¤æ¨ç†æœå‹™")
)

app = FastAPI(
    title="AIOT SmolLM2 AI Engine",
    description=service_description,
    version="2.0.0",
    lifespan=lifespan
)

# æ·»åŠ  CORS ä¸­é–“ä»¶ - å…è¨±è·¨åŸŸè«‹æ±‚ï¼Œæ”¯æ´å‰ç«¯æ‡‰ç”¨ç¨‹å¼å­˜å– API
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿç”¢ç’°å¢ƒæ‡‰è¨­å®šå…·é«”çš„ä¾†æºåŸŸåï¼Œæ­¤è™•ç‚ºé–‹ç™¼ä¾¿åˆ©è¨­ç‚ºæ‰€æœ‰åŸŸå
    allow_credentials=True,  # å…è¨±æ”œå¸¶èªè­‰è³‡è¨Šï¼ˆcookiesã€headersï¼‰
    allow_methods=["*"],  # å…è¨±æ‰€æœ‰ HTTP æ–¹æ³•ï¼ˆGETã€POSTã€PUTã€DELETE ç­‰ï¼‰
    allow_headers=["*"],  # å…è¨±æ‰€æœ‰ HTTP æ¨™é ­
)

@app.get("/health", response_model=HealthResponse)
async def health_check() -> HealthResponse:
    """
    æª¢æŸ¥ AI æœå‹™å¥åº·ç‹€æ…‹ã€‚
    
    æœ¬ç«¯é»ç”¨æ–¼ç›£æ§ç³»çµ±é‹è¡Œç‹€æ…‹ï¼Œæª¢æŸ¥ AI æ¨¡å‹æ˜¯å¦å·²è¼‰å…¥ä¸¦å¯æ­£å¸¸ä½¿ç”¨ã€‚
    é€šå¸¸è¢«è² è¼‰å‡è¡¡å™¨ã€å®¹å™¨ç·¨æ’ç³»çµ±æˆ–ç›£æ§å·¥å…·å‘¼å«ã€‚
    
    Returns:
        HealthResponse: åŒ…å«æœå‹™ç‹€æ…‹ã€æ¨¡å‹è³‡è¨Šå’Œå¯ç”¨æ€§çš„å¥åº·æª¢æŸ¥å›æ‡‰
        
    Raises:
        HTTPException: ç•¶æœå‹™æœªåˆå§‹åŒ–ï¼ˆ503ï¼‰æˆ–ç™¼ç”Ÿå…§éƒ¨éŒ¯èª¤ï¼ˆ500ï¼‰æ™‚æ‹‹å‡º
        
    Examples:
        ```bash
        curl -X GET http://localhost:8021/health
        ```
        
        æ­£å¸¸å›æ‡‰:
        ```json
        {
            "status": "healthy",
            "model": "HuggingFaceTB/SmolLM2-135M-Instruct",
            "available": true,
            "message": "SmolLM2 AI Service is running normally"
        }
        ```
        
    Note:
        - ç‹€æ…‹ç¢¼ 200ï¼šæœå‹™æ­£å¸¸é‹è¡Œ
        - ç‹€æ…‹ç¢¼ 503ï¼šæœå‹™ä¸å¯ç”¨æˆ–æœªåˆå§‹åŒ–
        - ç‹€æ…‹ç¢¼ 500ï¼šå…§éƒ¨ä¼ºæœå™¨éŒ¯èª¤
    """
    try:
        # æª¢æŸ¥ AI æœå‹™æ˜¯å¦å·²åˆå§‹åŒ–
        if not ai_service:
            raise HTTPException(status_code=503, detail="AI Service not initialized")
        
        # ç²å–æœå‹™å¥åº·ç‹€æ…‹
        health_status = ai_service.get_health_status()
        
        # æ ¹æ“šå¥åº·ç‹€æ…‹å›å‚³ç›¸æ‡‰çµæœ
        if health_status["available"]:
            return HealthResponse(
                status="healthy",
                model=health_status["model"],
                available=True,
                message="SmolLM2 AI Service is running normally"
            )
        else:
            raise HTTPException(
                status_code=503, 
                detail=f"AI Service unhealthy: {health_status}"
            )
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/generate", response_model=GenerateResponse)
async def generate_response(request: GenerateRequest) -> GenerateResponse:
    """
    ç”¢ç”Ÿå–®è¼ªæ–‡å­—å›æ‡‰ã€‚
    
    æœ¬ç«¯é»è™•ç†å–®æ¬¡æ–‡å­—ç”Ÿæˆè«‹æ±‚ï¼Œä¸ä¿ç•™å°è©±æ­·å²ã€‚é©ç”¨æ–¼ç¨ç«‹çš„æ–‡å­—ç”Ÿæˆä»»å‹™ï¼Œ
    å¦‚æ–‡ç« æ‘˜è¦ã€å•ç­”ã€æ–‡å­—ç¿»è­¯ç­‰å ´æ™¯ã€‚
    
    Args:
        request (GenerateRequest): åŒ…å«æç¤ºè©ã€RAG è¨­å®šå’Œåœ–åƒ URL çš„è«‹æ±‚ç‰©ä»¶
            - prompt (str): ç”¨æˆ¶è¼¸å…¥çš„æç¤ºè©
            - use_rag (bool): æ˜¯å¦ä½¿ç”¨ RAG æª¢ç´¢å¢å¼·ç”Ÿæˆï¼Œé è¨­ç‚º False
            - image_url (Optional[str]): åœ–åƒ URLï¼ˆSmolLM2 ä¸æ”¯æ´ï¼Œæœƒè¢«å¿½ç•¥ï¼‰
    
    Returns:
        GenerateResponse: åŒ…å«ç”Ÿæˆçµæœã€ä¾†æºè³‡æ–™å’Œæ¨¡å‹è³‡è¨Šçš„å›æ‡‰ç‰©ä»¶
        
    Raises:
        HTTPException: 
            - 503: AI æœå‹™ä¸å¯ç”¨
            - 500: ç”Ÿæˆéç¨‹ç™¼ç”ŸéŒ¯èª¤
    
    Examples:
        ```bash
        curl -X POST http://localhost:8021/generate \
             -H "Content-Type: application/json" \
             -d '{"prompt":"ä»€éº¼æ˜¯äººå·¥æ™ºæ…§ï¼Ÿ","use_rag":false}'
        ```
        
        ä½¿ç”¨ RAG æª¢ç´¢:
        ```bash
        curl -X POST http://localhost:8021/generate \
             -H "Content-Type: application/json" \
             -d '{"prompt":"è§£é‡‹é‡å­è¨ˆç®—","use_rag":true}'
        ```
        
    Note:
        - å–®è¼ªå°è©±ä¸ä¿ç•™æ­·å²è¨˜éŒ„ï¼Œæ¯æ¬¡è«‹æ±‚éƒ½æ˜¯ç¨ç«‹çš„
        - RAG åŠŸèƒ½éœ€è¦å…ˆä¸Šå‚³ç›¸é—œæ–‡æª”åˆ°å‘é‡è³‡æ–™åº«
        - åœ–åƒè™•ç†åŠŸèƒ½åœ¨ SmolLM2-135M ä¸­ä¸è¢«æ”¯æ´
    """
    try:
        if not ai_service:
            raise HTTPException(status_code=503, detail="AI Service not available")
        
        result = ai_service.generate_response(
            prompt=request.prompt,
            use_rag=request.use_rag,
            image_url=request.image_url
        )
        
        if result["success"]:
            return GenerateResponse(
                success=True,
                response=result["response"],
                sources=result.get("sources", []),
                model=result["model"]
            )
        else:
            raise HTTPException(
                status_code=500,
                detail=result.get("error", "Generation failed")
            )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Generate response failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/conversational", response_model=GenerateResponse)
async def conversational_response(request: ConversationalRequest) -> GenerateResponse:
    """
    ç”¢ç”Ÿå…·è¨˜æ†¶åŠŸèƒ½çš„å°è©±å›æ‡‰ã€‚
    
    æœ¬ç«¯é»æ”¯æ´å¤šè¼ªå°è©±ï¼Œèƒ½å¤ è¨˜ä½ä¹‹å‰çš„å°è©±å…§å®¹ä¸¦æ“šæ­¤ç”Ÿæˆé€£è²«çš„å›æ‡‰ã€‚
    åƒ…åœ¨ä½¿ç”¨ LangChain ç‰ˆæœ¬çš„æœå‹™æ™‚æ‰å…·å‚™å®Œæ•´çš„è¨˜æ†¶åŠŸèƒ½ã€‚
    
    Args:
        request (ConversationalRequest): åŒ…å«æç¤ºè©ã€RAG è¨­å®šå’Œåœ–åƒ URL çš„å°è©±è«‹æ±‚
            - prompt (str): ç”¨æˆ¶ç•¶å‰è¼¸å…¥çš„è¨Šæ¯
            - use_rag (bool): æ˜¯å¦çµåˆ RAG æª¢ç´¢ï¼Œé è¨­ç‚º False  
            - image_url (Optional[str]): åœ–åƒ URLï¼ˆç›®å‰ä¸æ”¯æ´ï¼‰
    
    Returns:
        GenerateResponse: åŒ…å«å°è©±å›æ‡‰ã€ç›¸é—œä¾†æºå’Œæ¨¡å‹è³‡è¨Š
        
    Raises:
        HTTPException:
            - 503: AI æœå‹™ä¸å¯ç”¨æˆ–æœªåˆå§‹åŒ–
            - 500: å°è©±ç”Ÿæˆéç¨‹ç™¼ç”ŸéŒ¯èª¤
    
    Examples:
        ç¬¬ä¸€è¼ªå°è©±:
        ```bash
        curl -X POST http://localhost:8021/conversational \
             -H "Content-Type: application/json" \
             -d '{"prompt":"ä½ å¥½ï¼Œæˆ‘æ˜¯å°æ˜","use_rag":false}'
        ```
        
        å¾ŒçºŒå°è©±ï¼ˆæœƒè¨˜ä½ä¹‹å‰æåˆ°çš„åå­—ï¼‰:
        ```bash
        curl -X POST http://localhost:8021/conversational \
             -H "Content-Type: application/json" \
             -d '{"prompt":"æˆ‘å‰›æ‰èªªæˆ‘å«ä»€éº¼åå­—ï¼Ÿ","use_rag":false}'
        ```
        
    Note:
        - å°è©±è¨˜æ†¶åƒ…åœ¨ LangChain ç‰ˆæœ¬ä¸­æœ‰æ•ˆ
        - Simple ç‰ˆæœ¬æœƒå°‡æ¯æ¬¡è«‹æ±‚è¦–ç‚ºç¨ç«‹å°è©±
        - è¨˜æ†¶åŠŸèƒ½ä¿ç•™æœ€è¿‘ 10 æ¢è¨Šæ¯ï¼ˆ5 è¼ªå°è©±ï¼‰
        - å¯é€é /memory/reset ç«¯é»æ¸…é™¤å°è©±è¨˜æ†¶
    """
    try:
        if not ai_service:
            raise HTTPException(status_code=503, detail="AI Service not available")
        
        result = ai_service.generate_conversational_response(
            prompt=request.prompt,
            use_rag=request.use_rag,
            image_url=request.image_url
        )
        
        if result["success"]:
            return GenerateResponse(
                success=True,
                response=result["response"],
                sources=result.get("sources", []),
                model=result["model"]
            )
        else:
            raise HTTPException(
                status_code=500,
                detail=result.get("error", "Generation failed")
            )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Conversational response failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/stream")
async def stream_generate(request: GenerateRequest) -> StreamingResponse:
    """
    ä¸²æµæ–‡å­—ç”Ÿæˆå›æ‡‰ã€‚
    
    æœ¬ç«¯é»æä¾›å³æ™‚æ–‡å­—ç”Ÿæˆæœå‹™ï¼Œä»¥ä¸²æµæ–¹å¼é€æ­¥è¼¸å‡ºç”Ÿæˆå…§å®¹ï¼Œ
    æå‡ç”¨æˆ¶é«”é©—ä¸¦æ¸›å°‘ç­‰å¾…æ™‚é–“ã€‚é©ç”¨æ–¼éœ€è¦å³æ™‚å›é¥‹çš„å ´æ™¯ã€‚
    
    Args:
        request (GenerateRequest): ä¸²æµç”Ÿæˆè«‹æ±‚ç‰©ä»¶
            - prompt (str): ç”¨æˆ¶è¼¸å…¥çš„æç¤ºè©
            - use_rag (bool): RAG è¨­å®šï¼ˆä¸²æµæ¨¡å¼ä¸‹æš‚ä¸æ”¯æ´ï¼‰
            - image_url (Optional[str]): åœ–åƒ URLï¼ˆç›®å‰ä¸æ”¯æ´ï¼‰
    
    Returns:
        StreamingResponse: SSE (Server-Sent Events) æ ¼å¼çš„ä¸²æµå›æ‡‰
        
    Raises:
        HTTPException:
            - 503: AI æœå‹™ä¸å¯ç”¨
            - 500: ä¸²æµç”Ÿæˆéç¨‹ç™¼ç”ŸéŒ¯èª¤
    
    Examples:
        JavaScript ä¸²æµè™•ç†:
        ```javascript
        fetch('http://localhost:8021/stream', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({prompt: 'èªªä¸€å€‹æ•…äº‹', use_rag: false})
        }).then(response => {
            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            
            function readStream() {
                return reader.read().then(({done, value}) => {
                    if (done) return;
                    const chunk = decoder.decode(value);
                    console.log(chunk); // è™•ç†æ¯å€‹æ–‡å­—å€å¡Š
                    return readStream();
                });
            }
            readStream();
        });
        ```
        
        cURL ä¸²æµè«‹æ±‚:
        ```bash
        curl -X POST http://localhost:8021/stream \
             -H "Content-Type: application/json" \
             -d '{"prompt":"å¯«ä¸€é¦–è©©","use_rag":false}' \
             --no-buffer
        ```
        
    Note:
        - ä¸²æµè¼¸å‡ºä»¥ "data: " é–‹é ­ï¼ŒçµæŸæ™‚ç™¼é€ "data: [DONE]"
        - ç”±æ–¼ SmolLM2 ä¸åŸç”Ÿæ”¯æ´ä¸²æµï¼Œæ­¤å¯¦ç¾ç‚ºæ¨¡æ“¬ä¸²æµ
        - ä¸²æµå›æ‡‰ä½¿ç”¨ text/plain åª’é«”é¡å‹
        - è¨­å®š Cache-Control å’Œ Connection æ¨™é ­ä»¥ä¿æŒé€£ç·š
    """
    try:
        if not ai_service:
            raise HTTPException(status_code=503, detail="AI Service not available")
        
        def generate_stream():
            try:
                for chunk in ai_service.stream_generate(
                    prompt=request.prompt,
                    image_url=request.image_url
                ):
                    yield f"data: {chunk}\n\n"
                yield "data: [DONE]\n\n"
            except Exception as e:
                logger.error(f"Stream generation failed: {e}")
                yield f"data: Error: {str(e)}\n\n"
        
        return StreamingResponse(
            generate_stream(),
            media_type="text/plain",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive"
            }
        )
    except Exception as e:
        logger.error(f"Stream endpoint failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/documents")
async def upload_documents(request: DocumentUploadRequest) -> Dict[str, Any]:
    """
    ä¸Šå‚³æ–‡ä»¶åˆ° RAG ç³»çµ±ã€‚
    
    æœ¬ç«¯é»å°‡æ–‡æœ¬æ–‡ä»¶åˆ‡åˆ†æˆå°å€å¡Šä¸¦å»ºç«‹å‘é‡åµŒå…¥ï¼Œå­˜å„²åˆ° Chroma å‘é‡è³‡æ–™åº«ä¸­ã€‚
    é€™äº›æ–‡ä»¶å°‡ç”¨æ–¼ RAG æª¢ç´¢å¢å¼·ç”Ÿæˆï¼Œæä¾›æ›´ç²¾ç¢ºçš„ä¸Šä¸‹æ–‡è³‡è¨Šã€‚
    
    Args:
        request (DocumentUploadRequest): æ–‡ä»¶ä¸Šå‚³è«‹æ±‚ç‰©ä»¶
            - documents (List[str]): è¦ä¸Šå‚³çš„æ–‡æœ¬æ–‡ä»¶åˆ—è¡¨
    
    Returns:
        Dict[str, Any]: ä¸Šå‚³çµæœè³‡è¨Š
            - success (bool): æ˜¯å¦æˆåŠŸä¸Šå‚³
            - message (str): å›æ‡‰è¨Šæ¯
            - documents_added (int): æˆåŠŸæ·»åŠ çš„æ–‡ä»¶æ•¸é‡
        
    Raises:
        HTTPException:
            - 503: AI æœå‹™ä¸å¯ç”¨æˆ–å‘é‡è³‡æ–™åº«æœªåˆå§‹åŒ–
            - 500: æ–‡ä»¶è™•ç†æˆ–ä¸Šå‚³éç¨‹ç™¼ç”ŸéŒ¯èª¤
    
    Examples:
        å–®ä¸€æ–‡ä»¶ä¸Šå‚³:
        ```bash
        curl -X POST http://localhost:8021/documents \
             -H "Content-Type: application/json" \
             -d '{"documents":["äººå·¥æ™ºæ…§æ˜¯æ¨¡æ“¬äººé¡æ™ºèƒ½çš„æŠ€è¡“..."]}'        
        ```
        
        å¤šä¸ªæ–‡ä»¶ä¸Šå‚³:
        ```bash
        curl -X POST http://localhost:8021/documents \
             -H "Content-Type: application/json" \
             -d '{"documents":["æ–‡ä»¶1å…§å®¹...","æ–‡ä»¶2å…§å®¹..."]}'
        ```
        
        æˆåŠŸå›æ‡‰:
        ```json
        {
            "success": true,
            "message": "Successfully added 2 documents",
            "documents_added": 2
        }
        ```
        
    Note:
        - æ–‡ä»¶æœƒè¢«è‡ªå‹•åˆ‡åˆ†æˆ 1000 å­—ç¬¦çš„å€å¡Šï¼Œé‡ç–Š 200 å­—ç¬¦
        - ä¸Šå‚³å¾Œçš„æ–‡ä»¶æœƒæ°¸ä¹…å­˜å„²åœ¨ ./chroma_db ç›®éŒ„ä¸­
        - å»ºè­°åœ¨ä¸Šå‚³å¤§é‡æ–‡ä»¶å‰å…ˆæ¸¬è©¦å°‘é‡æ–‡ä»¶
        - æ”¯æ´çš„æ–‡ä»¶æ ¼å¼ç‚ºç´”æ–‡æœ¬ï¼Œä¸æ”¯æ´ PDFã€Word ç­‰æ ¼å¼
    """
    try:
        if not ai_service:
            raise HTTPException(status_code=503, detail="AI Service not available")
        
        result = ai_service.add_documents(request.documents)
        
        if result["success"]:
            return {
                "success": True,
                "message": f"Successfully added {len(request.documents)} documents",
                "documents_added": len(request.documents)
            }
        else:
            raise HTTPException(
                status_code=500,
                detail=result.get("error", "Failed to add documents")
            )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Document upload failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/memory/reset")
async def reset_memory() -> Dict[str, Any]:
    """
    é‡ç½®å°è©±è¨˜æ†¶ï¼ˆåƒ… LangChain ç‰ˆæœ¬æ”¯æ´ï¼‰ã€‚
    
    æœ¬ç«¯é»ç”¨æ–¼æ¸…é™¤æ‰€æœ‰å°è©±æ­·å²è¨˜éŒ„ï¼Œé‡æ–°é–‹å§‹ä¸€æ®µå…¨æ–°çš„å°è©±ã€‚
    åªæœ‰åœ¨ä½¿ç”¨ LangChain ç‰ˆæœ¬çš„æœå‹™æ™‚æ‰æœ‰æ•ˆï¼ŒSimple ç‰ˆæœ¬æ²’æœ‰è¨˜æ†¶åŠŸèƒ½ã€‚
    
    Returns:
        Dict[str, Any]: æ“ä½œçµæœè³‡è¨Š
            - success (bool): æ˜¯å¦æˆåŠŸé‡ç½®
            - message (str): æ“ä½œçµæœèªªæ˜
        
    Raises:
        HTTPException:
            - 503: AI æœå‹™ä¸å¯ç”¨
            - 500: è¨˜æ†¶é‡ç½®éç¨‹ç™¼ç”ŸéŒ¯èª¤
    
    Examples:
        ```bash
        curl -X POST http://localhost:8021/memory/reset
        ```
        
        LangChain ç‰ˆæœ¬æˆåŠŸå›æ‡‰:
        ```json
        {
            "success": true,
            "message": "Conversation memory reset successfully"
        }
        ```
        
        Simple ç‰ˆæœ¬å›æ‡‰:
        ```json
        {
            "success": false,
            "message": "Memory reset not supported in current service"
        }
        ```
        
    Note:
        - é€™å€‹æ“ä½œæ˜¯ä¸å¯é€†çš„ï¼Œé‡ç½®å¾Œç„¡æ³•æ¢å¾©ä¹‹å‰çš„å°è©±å…§å®¹
        - å»ºè­°åœ¨é–‹å§‹æ–°è©±é¡Œæˆ–å°è©±å…§å®¹éå¤šæ™‚ä½¿ç”¨
        - é‡ç½®å¾Œçš„ä¸‹ä¸€æ¬¡ /conversational è«‹æ±‚å°‡è¢«è¦–ç‚ºå…¨æ–°å°è©±
    """
    try:
        if not ai_service:
            raise HTTPException(status_code=503, detail="AI Service not available")
        
        # æª¢æŸ¥æ˜¯å¦æ˜¯ LangChain æœå‹™
        if hasattr(ai_service, 'reset_memory'):
            ai_service.reset_memory()
            return {"success": True, "message": "Conversation memory reset successfully"}
        else:
            return {"success": False, "message": "Memory reset not supported in current service"}
    except Exception as e:
        logger.error(f"Memory reset failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/memory/history")
async def get_conversation_history() -> Dict[str, Any]:
    """
    ç²å–å°è©±æ­·å²ï¼ˆåƒ… LangChain ç‰ˆæœ¬æ”¯æ´ï¼‰ã€‚
    
    æœ¬ç«¯é»è¿”å›ç•¶å‰å°è©±éšæ®µä¸­çš„æ‰€æœ‰æ­·å²è¨Šæ¯ï¼ŒåŒ…å«ç”¨æˆ¶è¼¸å…¥å’Œ AI å›æ‡‰ã€‚
    é€™å€‹åŠŸèƒ½åªåœ¨ LangChain ç‰ˆæœ¬ä¸­å¯ç”¨ï¼Œç”¨æ–¼èª¿è©¦å’Œç†è§£å°è©±ä¸Šä¸‹æ–‡ã€‚
    
    Returns:
        Dict[str, Any]: å°è©±æ­·å²è³‡è¨Š
            - success (bool): æ˜¯å¦æˆåŠŸç²å–æ­·å²
            - history (List[Dict]): å°è©±è¨˜éŒ„åˆ—è¡¨ï¼Œæ¯å€‹è¨˜éŒ„åŒ…å« role å’Œ content
            - message (str): ç‹€æ…‹èªªæ˜ï¼ˆç•¶ä¸æ”¯æ´æ™‚ï¼‰
        
    Raises:
        HTTPException:
            - 503: AI æœå‹™ä¸å¯ç”¨
            - 500: ç²å–æ­·å²éç¨‹ç™¼ç”ŸéŒ¯èª¤
    
    Examples:
        ```bash
        curl -X GET http://localhost:8021/memory/history
        ```
        
        LangChain ç‰ˆæœ¬æˆåŠŸå›æ‡‰:
        ```json
        {
            "success": true,
            "history": [
                {"role": "human", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯å°æ˜"},
                {"role": "ai", "content": "ä½ å¥½å°æ˜ï¼å¾ˆé«˜èˆˆèªè­˜ä½ ã€‚"},
                {"role": "human", "content": "æˆ‘å‰›æ‰èªªæˆ‘å«ä»€éº¼ï¼Ÿ"},
                {"role": "ai", "content": "ä½ å‰›æ‰èªªä½ å«å°æ˜ã€‚"}
            ]
        }
        ```
        
        Simple ç‰ˆæœ¬å›æ‡‰:
        ```json
        {
            "success": false,
            "message": "Conversation history not supported in current service"
        }
        ```
        
    Note:
        - æ­·å²è¨˜éŒ„æŒ‰æ™‚é–“é †åºæ’åˆ—ï¼Œæœ€æ–°çš„è¨Šæ¯åœ¨æœ€å¾Œ
        - role æ¬„ä½å€¼ç‚º "human" æˆ– "ai"ï¼Œåˆ†åˆ¥ä»£è¡¨ç”¨æˆ¶è¼¸å…¥å’Œ AI å›æ‡‰
        - æ­¤ç«¯é»ä¸»è¦ç”¨æ–¼èª¿è©¦å’Œç›£æ§å°è©±ç‹€æ…‹
        - å°è©±æ­·å²åœ¨æœå‹™é‡å•Ÿå¾Œæœƒè¢«æ¸…é™¤
    """
    try:
        if not ai_service:
            raise HTTPException(status_code=503, detail="AI Service not available")
        
        # æª¢æŸ¥æ˜¯å¦æ˜¯ LangChain æœå‹™
        if hasattr(ai_service, 'get_conversation_history'):
            history = ai_service.get_conversation_history()
            return {
                "success": True, 
                "history": [{"role": msg.type, "content": msg.content} for msg in history]
            }
        else:
            return {"success": False, "message": "Conversation history not supported in current service"}
    except Exception as e:
        logger.error(f"Get conversation history failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    """
    æ‡‰ç”¨ç¨‹å¼é€²å…¥é»ã€‚
    
    ç•¶ç›´æ¥åŸ·è¡Œæ­¤è…³æœ¬æ™‚å•Ÿå‹• FastAPI é–‹ç™¼ä¼ºæœå™¨ã€‚æ”¯æ´ç†±é‡è¼‰å’Œè©³ç´°æ—¥èªŒè¼¸å‡ºï¼Œ
    æ–¹ä¾¿é–‹ç™¼å’Œæ¸¬è©¦ AI æœå‹™åŠŸèƒ½ã€‚
    
    ç’°å¢ƒè®Šæ•¸:
        PORT: ä¼ºæœå™¨ç«¯å£è™Ÿï¼Œé è¨­ç‚º 8021
        USE_LANGCHAIN: é¸æ“‡æœå‹™é¡å‹ (true/false)ï¼Œé è¨­ç‚º true
    
    Examples:
        ç›´æ¥å•Ÿå‹•ï¼š
        ```bash
        python main.py
        ```
        
        æŒ‡å®šç«¯å£ï¼š
        ```bash
        PORT=8022 python main.py
        ```
        
        ä½¿ç”¨ Simple æœå‹™ï¼š
        ```bash
        USE_LANGCHAIN=false python main.py
        ```
        
    Note:
        - é–‹ç™¼æ¨¡å¼å•Ÿç”¨ç†±é‡è¼‰ï¼ˆreload=Trueï¼‰
        - ç›£è½æ‰€æœ‰ä»‹é¢ (0.0.0.0)ï¼Œé©ç”¨æ–¼å®¹å™¨åŒ–éƒ¨ç½²
        - ç”Ÿç”¢ç’°å¢ƒå»ºè­°ä½¿ç”¨ Gunicorn + Uvicorn Workers
    """
    # å¾ç’°å¢ƒè®Šæ•¸ç²å–ç«¯å£è™Ÿï¼Œé è¨­ç‚º 8021
    port = int(os.getenv("PORT", "8021"))
    
    # å•Ÿå‹• Uvicorn ASGI ä¼ºæœå™¨
    uvicorn.run(
        "main:app",           # FastAPI æ‡‰ç”¨ç¨‹å¼æ¨¡çµ„è·¯å¾‘
        host="0.0.0.0",       # ç›£è½æ‰€æœ‰ä»‹é¢ï¼Œæ”¯æ´å®¹å™¨åŒ–éƒ¨ç½²
        port=port,            # ä¼ºæœå™¨ç«¯å£
        reload=True,          # é–‹å•Ÿç†±é‡è¼‰ï¼Œæª”æ¡ˆè®Šæ›´æ™‚è‡ªå‹•é‡å•Ÿ
        log_level="info"      # è¨­å®šæ—¥èªŒç´šåˆ¥ç‚º INFO
    )